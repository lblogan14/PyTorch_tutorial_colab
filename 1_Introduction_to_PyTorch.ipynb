{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1. Introduction_to_PyTorch.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNpHFU/Vv2sHD951W9HO2IH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lblogan14/PyTorch_tutorial_colab/blob/main/1_Introduction_to_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PyTorch Tensors"
      ],
      "metadata": {
        "id": "QS5DrM1RW-SN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uwAs8EfpWb9x"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To create tensors,"
      ],
      "metadata": {
        "id": "GYeRQNSdXC6j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z = torch.zeros(5, 3)\n",
        "print(z)\n",
        "print(z.dtype)"
      ],
      "metadata": {
        "id": "qe_hjcKGXCT5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Above, we created a 5x3 matrix filled with zeros and queried its datatype to find out that the zeros are 32-bit floating point numbers, which is the default PyTorch.\n",
        "\n",
        "To create integers,"
      ],
      "metadata": {
        "id": "lR_-gBRTXPSe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "i = torch.ones((5, 3), dtype=torch.int16)\n",
        "print(i)"
      ],
      "metadata": {
        "id": "123xhFgHXNqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is common to intialize learning weights randomly, often with a specific seed for the pseudorandom number generator (PRNG) for reproducibility of results:"
      ],
      "metadata": {
        "id": "O3p0HLQ8XrXU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1)\n",
        "\n",
        "r1 = torch.rand(2,2)\n",
        "print('A random tensor:')\n",
        "print(r1)\n",
        "\n",
        "r2 = torch.rand(2,2)\n",
        "print('\\nA different random tensor:')\n",
        "print(r2) # new values\n",
        "\n",
        "torch.manual_seed(1)\n",
        "r3 = torch.rand(2,2)\n",
        "print('\\nShould match r1:')\n",
        "print(r3) # repeats values of r1 because of re-seed"
      ],
      "metadata": {
        "id": "HUHEVw4BXnJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch tensors perform arithmetic operations intuitively."
      ],
      "metadata": {
        "id": "Q9aUM2oEea30"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ones = torch.ones(2,3)\n",
        "print(ones)"
      ],
      "metadata": {
        "id": "S9dZl5ZncsjN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "twos = torch.ones(2,3) * 2 # every element is multiplied by 2\n",
        "print(twos)"
      ],
      "metadata": {
        "id": "0ObGLgQ_fCQw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "threes = ones + twos # addition allowed because shapes are similar\n",
        "print(threes) # tensors are added element-wise\n",
        "print(threes.shape) # this has the same dimensions as input tensors"
      ],
      "metadata": {
        "id": "P3l8x2iXfGyB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r1 = torch.rand(2,3)\n",
        "r2 = torch.rand(3,2)\n",
        "r3 = r1 + r2 # shapes are different"
      ],
      "metadata": {
        "id": "GLkU2mgkfQQ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Samples of the mathematical operations available:"
      ],
      "metadata": {
        "id": "ytDtl1cQfafN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r = torch.rand(2,2) - 0.5 * 2\n",
        "print('A random matrix, r:')\n",
        "print(r)"
      ],
      "metadata": {
        "id": "V8rr3cd8fXc-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Absolute value of r:')\n",
        "print(torch.abs(r))"
      ],
      "metadata": {
        "id": "VefABMp1fwxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Inverse sine of r:')\n",
        "print(torch.asin(r))"
      ],
      "metadata": {
        "id": "tjQFPI2Wf5FV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Determinant of r:')\n",
        "print(torch.det(r))\n",
        "print('\\nSingluar value decomposition of r:')\n",
        "print(torch.svd(r))"
      ],
      "metadata": {
        "id": "mSTeEpuEf8Ay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Standard deviation(1st) and average(2nd) of r:')\n",
        "print(torch.std_mean(r))\n",
        "print('\\nMaximum value of r:')\n",
        "print(torch.max(r))"
      ],
      "metadata": {
        "id": "u6dnYnyUgDwI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Size of r:')\n",
        "print(r.size())\n",
        "print('\\nSize of r.view(-1):')\n",
        "print(r.view(-1).size())"
      ],
      "metadata": {
        "id": "B2cNtE7k5Btx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PyTorch Models"
      ],
      "metadata": {
        "id": "kjkc79_kgT4I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch                        # for all things PyTorch\n",
        "import torch.nn as nn              # for torch.nn.Module, the parent object for PyTorch models\n",
        "import torch.nn.functional as F     # for the activation function"
      ],
      "metadata": {
        "id": "nLRDhaqRgNu1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Express the LeNet-5 model in code:"
      ],
      "metadata": {
        "id": "L4HMaN3dgsbf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LeNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet, self).__init__()\n",
        "        # 1 input image channel (black & white), 6 output channels, 3x3 square convolution kernel\n",
        "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
        "        # an affine operation: y = Wx + b\n",
        "        self.fc1 = nn.Linear(16 * 6*6, 120) # 6*6 from image dimension\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Max pooling over a (2,2) window\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2,2))\n",
        "        # If the size is a square you can only specify a single number\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = x.view(-1, self.num_flat_features(x))\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:] # all dimensions except the batch dimension\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features"
      ],
      "metadata": {
        "id": "lhRy7oHGgpul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This demonstrates the structure of a typical PyTorch model:\n",
        "* It inherits from `torch.nn.Module` - modules may be nested - in fact, even the `Conv2d` and `Linear` layer classes inherit from `torch.nn.Module`.\n",
        "* A model will have an `__init__()` function, where it instantiates its layers, and loads any data artifacts it may need.\n",
        "* A model will have a `forward()` function. This is where the actual computation happens.\n",
        "* We can build out our model class like any other Python class."
      ],
      "metadata": {
        "id": "EhjcDitZis3E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instantiate this object and run a sample input through it:"
      ],
      "metadata": {
        "id": "k6cPj_-focMs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net = LeNet()\n",
        "print(net) # what does the object tell us about itself?"
      ],
      "metadata": {
        "id": "Hs76s7XpiseG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = torch.rand(1, 1, 32, 32) # stand-in for a 32x32 black&white image\n",
        "print('Image batch shape:')\n",
        "print(input.shape)"
      ],
      "metadata": {
        "id": "Imkl6iG4okqK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = net(input) # we don not call forward() directly\n",
        "print('Raw output:')\n",
        "print(output)\n",
        "print(output.shape)"
      ],
      "metadata": {
        "id": "WLlZNiXBowsr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch models assume they are working on *batches* of data - for example, a batch of 16 of our image tiles would have the shape `(16, 1, 32, 32)`.\n",
        "\n",
        "We ask the model for an inference by calling it like a function: `net(input)`. The output of this call represents the model's confidence that the input represents a particular digit. The shape of the output also has a batch dimension."
      ],
      "metadata": {
        "id": "k0j5KfnOpDMf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Datasets and Dataloaders"
      ],
      "metadata": {
        "id": "V40-mr2ApgG_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ],
      "metadata": {
        "id": "QVpGsjtTo4cG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first thing we need to do is transform our incoming images into a PyTorch tensor."
      ],
      "metadata": {
        "id": "05MLBLKNp5Mr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
        ")\n",
        "\n",
        "'''\n",
        "For transofrms.Normalize, the arguments passed need to be \n",
        "calculated for mean and std in each channel. Then we can\n",
        "use those values as arguments in Normalize to make sure that\n",
        "the values after this transformation have mean of zero and std of 0.5\n",
        "'''"
      ],
      "metadata": {
        "id": "_vCnRF9Sp4gx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are two specified transofrmations for our input:\n",
        "* `transforms.ToTensor()` converts images loaded by Pillow into  PyTorch tensors.\n",
        "* `transforms.Normalize()` adjusts the values of the tensor so that their average is zero and their standard deviation is 0.5."
      ],
      "metadata": {
        "id": "6wUxF02JqMCa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we will create an instance of the CIFAR10 dataset. This is a set of 32x32 color image tiles representing 10 classes of objects:"
      ],
      "metadata": {
        "id": "jykN3pYNq2TS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = torchvision.datasets.CIFAR10(\n",
        "    root='./data',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")"
      ],
      "metadata": {
        "id": "IjTn7QU0qLVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once dataset is ready, we can give it to the `DataLoader`:"
      ],
      "metadata": {
        "id": "Zv2CSH-oraZr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainloader = torch.utils.data.DataLoader(\n",
        "    trainset,\n",
        "    batch_size=4,\n",
        "    shuffle=True,\n",
        "    num_workers=2\n",
        ")"
      ],
      "metadata": {
        "id": "gDS8T1jkrH_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `DataLoader` knows nothing about the data, but organizes the input tensors served by the `Dataset` into batches with the paraemeter we specify."
      ],
      "metadata": {
        "id": "Hnu30EAkrmHJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To visualize the batches our `DataLoader` serves:"
      ],
      "metadata": {
        "id": "D1WQOxw4r32j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "rEfhD1AkrlVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5 # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "# print labels\n",
        "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
      ],
      "metadata": {
        "id": "JtkKWXkasAC3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.std_mean(images)\n",
        "# check if the Normalize transform does work"
      ],
      "metadata": {
        "id": "GgjRDFOcwSaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training PyTorch Model"
      ],
      "metadata": {
        "id": "3LHwRp1_1iuC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "8IB04MJDwyje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, need training and test datasets."
      ],
      "metadata": {
        "id": "fJd3KkCv133r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
        ")\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(\n",
        "    root='./data',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    trainset,\n",
        "    batch_size=4,\n",
        "    shuffle=True,\n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(\n",
        "    root='./data',\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "testloader = torch.utils.data.DataLoader(\n",
        "    testset,\n",
        "    batch_size=4,\n",
        "    shuffle=False,\n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "metadata": {
        "id": "-HXYdpQY10Uf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run and check the output from `DataLoader`:"
      ],
      "metadata": {
        "id": "gP3vcbBj2uZD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def imshow(img):\n",
        "    img = img / 2 + 0.5 # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1,2,0)))\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "# print labels\n",
        "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
      ],
      "metadata": {
        "id": "1FNliUUd2sRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, build the model:"
      ],
      "metadata": {
        "id": "bFsXqazc3VPy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5*5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5*5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "net = Net()"
      ],
      "metadata": {
        "id": "cpQMAmwg3Ph4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The last ingredients are a loss function and an optimizer:"
      ],
      "metadata": {
        "id": "F21zyGvt4aP9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "X3CHaeT_4Zz4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cross-entropy loss is a typical loss function for classification models.\n",
        "\n",
        "Finally, all of this assembled into the training loop:"
      ],
      "metadata": {
        "id": "5cVHR_N34kkp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(2): # loop over the dataset multiple times\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, start=0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999: #print every 2000 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch+1, i+1, running_loss/2000))\n",
        "            running_loss = 0.\n",
        "print('Finish Training')"
      ],
      "metadata": {
        "id": "eCcWnOmD4jq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we did 2 training epochs (line 1). Each epoch has an inner loop that iterates over the training data (line 4), serving batches of transformed input images and their correct labels.\n",
        "\n",
        "**Zeroing the gradient** (line 8) is important! Gradients are accumulated over a batch; if we do not reset them for every batch, they will keep accumulating, which will provide incorrect gradient values, making learning impossible.\n",
        "\n",
        "We asked the model for its predictions on this batch in line 11, In line 12, we compute the loss - the difference between `outputs` and `labels`.\n",
        "\n",
        "In line 13, we do the `backward` pass, and calculate the gradients that will direct the learning.\n",
        "\n",
        "In line 14, the optimizer performs one learning step - it usees the gradients from the `backward()` call to nudge the learning weights in the direction it thinks will reduce the loss."
      ],
      "metadata": {
        "id": "fkr5v0MA6qGB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As a final step, we should check that the model is actually doing general learning, and not overfitting. This is why datasets are splitted into training and test subsets - to test the generality of the model, we ask it to make predictions on data it has not trained on:"
      ],
      "metadata": {
        "id": "hSMrnoaq8K3S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' %\n",
        "      (100 * correct/total))"
      ],
      "metadata": {
        "id": "j4W1-ncG49pD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "3EUxp9iq82Nw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}