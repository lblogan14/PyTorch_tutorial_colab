{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5. TensorBoard.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNK2mFGIak9D3YiV4tI58FF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lblogan14/PyTorch_tutorial_colab/blob/main/5_TensorBoard.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make sure we installed Pytorch, TorchVision, Matplotlib, and TensorBoard:\n",
        "\n",
        "`conda install pytorch torchvision -c`\n",
        "\n",
        "`conda install matplotlib tensorboard`"
      ],
      "metadata": {
        "id": "j-DAxlfG3elB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Introduction\n",
        "Let's train a variant of LeNet-5 against the Fashion-MNIST dataset"
      ],
      "metadata": {
        "id": "sjjM4ns53wYE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hEEu0hp43Htm"
      },
      "outputs": [],
      "source": [
        "# PyTorch model and training necessities\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "# Image datasets and image manipulation\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Image display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# PyTorch TensorBoard Support\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Showing Images in TensorBoard\n",
        "Adding sameple images from dataset to TensorBoard:"
      ],
      "metadata": {
        "id": "dxv0lOE64USA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Gather datasets and prepare them for consumption\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5,), (0.5,))]\n",
        ")\n",
        "\n",
        "# Store separate training and validations splits in ./data\n",
        "training_set = torchvision.datasets.FashionMNIST(\n",
        "    './data',\n",
        "    download=True,\n",
        "    train=True,\n",
        "    transform=transform\n",
        ")\n",
        "validation_set = torchvision.datasets.FashionMNIST(\n",
        "    './data',\n",
        "    download=True,\n",
        "    train=False,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "training_loader = torch.utils.data.DataLoader(training_set,\n",
        "                                              batch_size=4,\n",
        "                                              shuffle=True,\n",
        "                                              num_workers=2)\n",
        "validation_loader = torch.utils.data.DataLoader(validation_set,\n",
        "                                                batch_size=4,\n",
        "                                                shuffle=False,\n",
        "                                                num_workers=2)\n",
        "\n",
        "# Class labels\n",
        "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n",
        "\n",
        "def matplotlib_imshow(img, one_channel=False):\n",
        "    if one_channel:\n",
        "        img = img.mean(dim=0)\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    if one_channel:\n",
        "        plt.imshow(npimg, cmap='Greys')\n",
        "    else:\n",
        "        plt.imshow(np.transpose(npimg, (1,2,0)))\n",
        "\n",
        "# Extract a batch of 4 images\n",
        "dataiter = iter(training_loader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# Create a grid from the images and show\n",
        "img_grid = torchvision.utils.make_grid(images)\n",
        "matplotlib_imshow(img_grid, one_channel=True)"
      ],
      "metadata": {
        "id": "qGCpvYa14NaN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we use the `add_image()` call on `SummaryWriter` to log the image for consumption by TensorBoard, and we also call `flush()` to make sure it is written to disk right away:"
      ],
      "metadata": {
        "id": "-gUGF7rt5vfP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Default log_dir argument is \"runs\" - but it's good to be specific\n",
        "# torch.utils.tensorboard.SummaryWriter is import above\n",
        "writer = SummaryWriter('runs/fashion_mnist_experiment_1')\n",
        "\n",
        "# write image data to TensorBoard log dir\n",
        "writer.add_image('Four Fashion-MNIST Images', img_grid)\n",
        "writer.flush()\n",
        "\n",
        "# To view, start TensorBoard on the command line with\n",
        "%tensorboard --logdir=runs\n",
        "# and open a browser tab to http://localhost:6006/"
      ],
      "metadata": {
        "id": "TbUHPewy5uu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Graphing Scalars to Visualize Training\n",
        "TensorBoard is useful for tracking the progress and efficacy of training. We will run a training loop, track some metrics, and save the data for TensorBoard's consumption below."
      ],
      "metadata": {
        "id": "T4jsv-Gg8CdR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 4 * 4)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "net = Net()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "_JaEh5zN8CRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, let's train a single epoch, and evaluate the training vs. validation set losses every 100 batches:"
      ],
      "metadata": {
        "id": "YrU3ypTlEfIh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(validation_loader))\n",
        "for epoch in range(1): # loop over the dataset multiple times\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for i, data in enumerate(training_loader, 0):\n",
        "        # basic training loop\n",
        "        inputs, labels = data\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 1000 == 999:    # every 1000 mini-batches\n",
        "            print('Batch {}'.format(i+1))\n",
        "            # check against the validation set\n",
        "            running_vloss = 0.0\n",
        "\n",
        "            net.train(False) # Don't need to track gradients for validation\n",
        "\n",
        "            for j, vdata in enumerate(validation_loader, 0):\n",
        "                vinputs, vlabels = vdata\n",
        "                voutputs = net(vinputs)\n",
        "                vloss = criterion(voutputs, vlabels)\n",
        "                running_vloss += vloss.item()\n",
        "            net.train(True) # Turn gradients back on for training\n",
        "\n",
        "            avg_loss = running_loss / 1000\n",
        "            avg_vloss = running_vloss / len(validation_loader)\n",
        "\n",
        "            # log the running loss averaged per batch\n",
        "            writer.add_scalars('Training vs. Validation Loss',\n",
        "                               {'Training': avg_loss,\n",
        "                                'Validation:': avg_vloss},\n",
        "                               epoch * len(training_loader)+i)\n",
        "            running_vloss = 0.0\n",
        "print('Finished Training')\n",
        "writer.flush()"
      ],
      "metadata": {
        "id": "FZQg7Tis67cZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir=runs"
      ],
      "metadata": {
        "id": "YgbM3kUUHatf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Visualizing Model\n",
        "TensorBoard can also be used to examine the data flow within the model. To do this, call the `add_graph()` method with a model and sample input."
      ],
      "metadata": {
        "id": "jcSZjgI7MsBc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# again, grab a single mini-batch of images\n",
        "dataiter = iter(training_loader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# add_graph() will trace the sample input through the model\n",
        "# and render it as a graph\n",
        "writer.add_graph(net, images)\n",
        "writer.flush()"
      ],
      "metadata": {
        "id": "yFyMqmqzMhnt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir=runs"
      ],
      "metadata": {
        "id": "tzoDLMkTN3DL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Visualizing Dataset with Embeddings\n",
        "The 28x28 image tiles can be modeled as 784-dimensional vectors. It can be instructive to project this to a lower-dimensional representation. The `add_embedding()` method will project a set of data onto the three dimensions with highest variance, and display them as an interactive 3D chart.\n"
      ],
      "metadata": {
        "id": "9_0tvw1kOHTo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# select a random subset of data and corresponding labels:\n",
        "def select_n_random(data, labels, n=100):\n",
        "    assert len(data) == len(labels)\n",
        "\n",
        "    perm = torch.randperm(len(data))\n",
        "    return data[perm][:n], labels[perm][:n]\n",
        "\n",
        "# extract a random subset of data\n",
        "images, labels = select_n_random(training_set.data,\n",
        "                                 training_set.targets)\n",
        "\n",
        "# get the class labels for each image\n",
        "class_labels = [classes[label] for label in labels]\n",
        "\n",
        "# log embeddings\n",
        "features = images.view(-1, 28*28)\n",
        "\n",
        "\n",
        "# so far, we need the following to fix the error\n",
        "import tensorflow as tf\n",
        "import tensorboard as tb\n",
        "tf.io.gfile = tb.compat.tensorflow_stub.io.gfile\n",
        "\n",
        "writer.add_embedding(features,\n",
        "                     metadata=class_labels,\n",
        "                     label_img=images.unsqueeze(1)\n",
        "                     )\n",
        "writer.flush()\n",
        "writer.close()"
      ],
      "metadata": {
        "id": "4gbYZsoIN3i7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir=runs"
      ],
      "metadata": {
        "id": "PENzrWIYPyGT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}