{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "0. Learn_the_basics.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "KfZ7mt415dVJ",
        "cMay9btxhqlB",
        "Xe0vTYOpwA6O",
        "_GOT7azq4oLG",
        "pwhLM7gvBN0l",
        "d_mxIsnWJKrx",
        "tYnSeUWIz3fP",
        "I2CzhDgK7Hee",
        "vC5jH-y1UAEk"
      ],
      "authorship_tag": "ABX9TyN+9NlIsUGdTnBa3vOUnt0P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "419a4bbf620847ccae3b78057322ae60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e5457cbe66e84b32a4745aaa41030f98",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c5a02dbdca434b569c99dbfec643dd43",
              "IPY_MODEL_7ee88f924a8f442984e51488b863c287",
              "IPY_MODEL_a7b7ffe5cf734e97bf5d3396c1795309"
            ]
          }
        },
        "e5457cbe66e84b32a4745aaa41030f98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c5a02dbdca434b569c99dbfec643dd43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_15ec6e89af4c430b9220474b5556c738",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d02d0b3ad10f48228a610cebe39eea0a"
          }
        },
        "7ee88f924a8f442984e51488b863c287": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_df59e7e621e043d981c33982f2961662",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 26421880,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 26421880,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f9afabf7ea5b40a19cce5857a9cb1aea"
          }
        },
        "a7b7ffe5cf734e97bf5d3396c1795309": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fc2d37ef3bf848138f06b0c6c2266015",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 26422272/? [00:01&lt;00:00, 23047347.98it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1a0eacfc62e943239d818e24a83574f1"
          }
        },
        "15ec6e89af4c430b9220474b5556c738": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d02d0b3ad10f48228a610cebe39eea0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "df59e7e621e043d981c33982f2961662": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f9afabf7ea5b40a19cce5857a9cb1aea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fc2d37ef3bf848138f06b0c6c2266015": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1a0eacfc62e943239d818e24a83574f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "87f58adad841463e88370cdaf1157bf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_50d96606dbc54c3a898fc7b79cfc01ac",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f3cdc5614c6e4ba782ca980537b4faa0",
              "IPY_MODEL_9be7507aa2c54943aa37c9c1572ae883",
              "IPY_MODEL_b993644a9e8d4eb8b5436db268e46500"
            ]
          }
        },
        "50d96606dbc54c3a898fc7b79cfc01ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f3cdc5614c6e4ba782ca980537b4faa0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0974e77f88cb4ab79bf3b21fab15cee9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e5d805b154b44542a7696efe3c1314c5"
          }
        },
        "9be7507aa2c54943aa37c9c1572ae883": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3c0a14ac95794a188db2cd1bef4c2908",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 29515,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 29515,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_88dc40ed93cd459eb48277d453379ede"
          }
        },
        "b993644a9e8d4eb8b5436db268e46500": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5f7bfe13e4d242b789e24b3c35d3e862",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 29696/? [00:00&lt;00:00, 135588.44it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_988bda4cd7164d47b8b70fe1d49c5af3"
          }
        },
        "0974e77f88cb4ab79bf3b21fab15cee9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e5d805b154b44542a7696efe3c1314c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3c0a14ac95794a188db2cd1bef4c2908": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "88dc40ed93cd459eb48277d453379ede": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5f7bfe13e4d242b789e24b3c35d3e862": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "988bda4cd7164d47b8b70fe1d49c5af3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7fa69be983224ecfb38ee4f13f035327": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_82bef50d8e6c4d29894b4ccad5c1065f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b7cee5f62b0b4611a716ab9f61fdb513",
              "IPY_MODEL_7648236b931e44e694161542e283a6d1",
              "IPY_MODEL_9694c61ba4a24fc1b99ed6371db6ccda"
            ]
          }
        },
        "82bef50d8e6c4d29894b4ccad5c1065f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b7cee5f62b0b4611a716ab9f61fdb513": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f4098833922e43ea88f4a9f15b12a63f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f2b4b07c615541c9ae069f613a0730f3"
          }
        },
        "7648236b931e44e694161542e283a6d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7f5a7ebfa6524e3195b89ae812281ae1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 4422102,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4422102,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_67fe1cdd62d444c78d506d5828712e33"
          }
        },
        "9694c61ba4a24fc1b99ed6371db6ccda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_aa551cf29ec54fbeb55345d4c5f18b30",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4422656/? [00:00&lt;00:00, 8603047.83it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7d345a6cf9894208ba1402d5ffee4bf7"
          }
        },
        "f4098833922e43ea88f4a9f15b12a63f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f2b4b07c615541c9ae069f613a0730f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7f5a7ebfa6524e3195b89ae812281ae1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "67fe1cdd62d444c78d506d5828712e33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aa551cf29ec54fbeb55345d4c5f18b30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7d345a6cf9894208ba1402d5ffee4bf7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4056826685284125beca22999f580619": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_930a88464ac74cbabc801606ed164ff9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e9211cb0c2724cd9a00858b7b141b634",
              "IPY_MODEL_cbe4427545e043a5953248c20226dde2",
              "IPY_MODEL_178b3c3b56e54a04b241d02245a7a228"
            ]
          }
        },
        "930a88464ac74cbabc801606ed164ff9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e9211cb0c2724cd9a00858b7b141b634": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b339ed400474440eadb09ce376320501",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0e87d9991b1648c284b0d973d92df7ed"
          }
        },
        "cbe4427545e043a5953248c20226dde2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3878e5a4cbe440df95178491a2c4af1f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 5148,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5148,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_135ef5f071c043c7b87265278271ac71"
          }
        },
        "178b3c3b56e54a04b241d02245a7a228": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3ace030cd8ea44dc9daa77edd7ace396",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 6144/? [00:00&lt;00:00, 134565.36it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8bd738ef2c4a4aed92575e91471c4335"
          }
        },
        "b339ed400474440eadb09ce376320501": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0e87d9991b1648c284b0d973d92df7ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3878e5a4cbe440df95178491a2c4af1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "135ef5f071c043c7b87265278271ac71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3ace030cd8ea44dc9daa77edd7ace396": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8bd738ef2c4a4aed92575e91471c4335": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "473cfa1f8072414387a199f9ff86cfa0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_296e0f81e3014bb88498cfa36c3c2bb2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7a7b5ed4d8954610a4f89896e3dcd673",
              "IPY_MODEL_185d6615e70d4588bfe8263bdd4f01be",
              "IPY_MODEL_31bf4fc07cce4b0c896813614112ddd5"
            ]
          }
        },
        "296e0f81e3014bb88498cfa36c3c2bb2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7a7b5ed4d8954610a4f89896e3dcd673": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_008957d3e5dc444b96480f7835c05c13",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b4469030380b412cb38a3725f5dccd89"
          }
        },
        "185d6615e70d4588bfe8263bdd4f01be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e7c4261315314a5ab14ac7066f5fa466",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 553433881,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 553433881,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ca200b2163744e38a2ac9d8816ff7df9"
          }
        },
        "31bf4fc07cce4b0c896813614112ddd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_51fdfe40d8d545f793dbeee23627db2c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 528M/528M [00:03&lt;00:00, 187MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5cd04dc333e24fe391c8881a6ba3a4ee"
          }
        },
        "008957d3e5dc444b96480f7835c05c13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b4469030380b412cb38a3725f5dccd89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e7c4261315314a5ab14ac7066f5fa466": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ca200b2163744e38a2ac9d8816ff7df9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "51fdfe40d8d545f793dbeee23627db2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5cd04dc333e24fe391c8881a6ba3a4ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lblogan14/PyTorch_tutorial_colab/blob/main/0_Learn_the_basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#QUICKSTART"
      ],
      "metadata": {
        "id": "KfZ7mt415dVJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Working with data\n",
        "* `torch.utils.data.Dataset` stores the samples and their corresponding labaels.\n",
        "* `torch.utils.data.DataLoader` wraps an iterable around the `Dataset`.\n"
      ],
      "metadata": {
        "id": "cMay9btxhqlB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Aa04d4DFg1e8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Lambda, Compose\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch offers domain-specific libraries such as `TorchText`, `TorchVision`, and `TorchAudio`, all of which include `datasets`. The `torchvision.datasets` module contains `Dataset` objects for many real-world vision data like CIFAR, COCO, etc. Every TorchVision `Dataset` includes two arguments: `transform` and `target_transform` to modify the samples and labels respectively."
      ],
      "metadata": {
        "id": "Ls4rVlE9iis9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download training data from open datasets\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root='data',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")"
      ],
      "metadata": {
        "id": "-pPQY4qBidI0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423,
          "referenced_widgets": [
            "419a4bbf620847ccae3b78057322ae60",
            "e5457cbe66e84b32a4745aaa41030f98",
            "c5a02dbdca434b569c99dbfec643dd43",
            "7ee88f924a8f442984e51488b863c287",
            "a7b7ffe5cf734e97bf5d3396c1795309",
            "15ec6e89af4c430b9220474b5556c738",
            "d02d0b3ad10f48228a610cebe39eea0a",
            "df59e7e621e043d981c33982f2961662",
            "f9afabf7ea5b40a19cce5857a9cb1aea",
            "fc2d37ef3bf848138f06b0c6c2266015",
            "1a0eacfc62e943239d818e24a83574f1",
            "87f58adad841463e88370cdaf1157bf4",
            "50d96606dbc54c3a898fc7b79cfc01ac",
            "f3cdc5614c6e4ba782ca980537b4faa0",
            "9be7507aa2c54943aa37c9c1572ae883",
            "b993644a9e8d4eb8b5436db268e46500",
            "0974e77f88cb4ab79bf3b21fab15cee9",
            "e5d805b154b44542a7696efe3c1314c5",
            "3c0a14ac95794a188db2cd1bef4c2908",
            "88dc40ed93cd459eb48277d453379ede",
            "5f7bfe13e4d242b789e24b3c35d3e862",
            "988bda4cd7164d47b8b70fe1d49c5af3",
            "7fa69be983224ecfb38ee4f13f035327",
            "82bef50d8e6c4d29894b4ccad5c1065f",
            "b7cee5f62b0b4611a716ab9f61fdb513",
            "7648236b931e44e694161542e283a6d1",
            "9694c61ba4a24fc1b99ed6371db6ccda",
            "f4098833922e43ea88f4a9f15b12a63f",
            "f2b4b07c615541c9ae069f613a0730f3",
            "7f5a7ebfa6524e3195b89ae812281ae1",
            "67fe1cdd62d444c78d506d5828712e33",
            "aa551cf29ec54fbeb55345d4c5f18b30",
            "7d345a6cf9894208ba1402d5ffee4bf7",
            "4056826685284125beca22999f580619",
            "930a88464ac74cbabc801606ed164ff9",
            "e9211cb0c2724cd9a00858b7b141b634",
            "cbe4427545e043a5953248c20226dde2",
            "178b3c3b56e54a04b241d02245a7a228",
            "b339ed400474440eadb09ce376320501",
            "0e87d9991b1648c284b0d973d92df7ed",
            "3878e5a4cbe440df95178491a2c4af1f",
            "135ef5f071c043c7b87265278271ac71",
            "3ace030cd8ea44dc9daa77edd7ace396",
            "8bd738ef2c4a4aed92575e91471c4335"
          ]
        },
        "outputId": "e5905da1-4ab6-452e-c8f4-4e990b57afc7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "419a4bbf620847ccae3b78057322ae60",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/26421880 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "87f58adad841463e88370cdaf1157bf4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/29515 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7fa69be983224ecfb38ee4f13f035327",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/4422102 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4056826685284125beca22999f580619",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/5148 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download test data from open datasets.\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root='data',\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")"
      ],
      "metadata": {
        "id": "IULvQijwj_X9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pass the `Dataset` as an argument to `DataLoader`. This wraps an iterable over the dataset, and supports automatic batching, sampling, shuffling, and multiprocess data loading. If we define a batch size of 64, i.e. each element in the dataloader iterable will return a batch of 64 features and labels."
      ],
      "metadata": {
        "id": "UIVke9HqkToP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "# Create data loaders\n",
        "train_dataloader = DataLoader(training_data,\n",
        "                              batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data,\n",
        "                             batch_size=batch_size)\n",
        "\n",
        "for X,y in test_dataloader:\n",
        "    print('Shape of X [N, C, H, W]: ', X.shape)\n",
        "    print('Shape of y: ', y.shape, y.dtype)\n",
        "    break"
      ],
      "metadata": {
        "id": "_2qg3VTakSCH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df3d3ce9-d83e-42d9-e62f-b420786774d9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X [N, C, H, W]:  torch.Size([64, 1, 28, 28])\n",
            "Shape of y:  torch.Size([64]) torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Models\n",
        "To define a neural network in PyTorch, we need to create a class that inherits from `nn.Module`.\n",
        "\n",
        "We define the layers of the network in the `__init__` function and specify how data will pass through the network in the `forward` function. To accelerate operations in the neural network, we move it to the GPU if available"
      ],
      "metadata": {
        "id": "g03wwyFylR1-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get cpu or gpu device for training\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'Using {device} device')"
      ],
      "metadata": {
        "id": "YGdlqjVUlJbP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aadb031a-6656-45b2-8272-b4e942d90bea"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        \n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10)\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "9h4OfVY9mRnn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "id": "izKv3e4Vm5OO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "985d6341-8b1b-45b4-83b0-da0fcc8d18ac"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Optimizing the Model Parameters"
      ],
      "metadata": {
        "id": "Pb6BhyrOnCeu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To train a model, we need to define a loss function and an optimizer"
      ],
      "metadata": {
        "id": "byyrSB8KnGhG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "kmJ-KwJ2m-pu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In a single training loop, the model makes predictions on the training dataset (fed to it in batches), and backpropagates the prediction error to adjust the model's parameters."
      ],
      "metadata": {
        "id": "chWKTO4PnYxz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Compute prediction error\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch*len(X)\n",
        "            print(f'loss: {loss:>7f} [{current:>5d}/{size:>5d}]')"
      ],
      "metadata": {
        "id": "n15V6bQLnXgG"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Also check the model's performance against the test dataset to ensure it is learning"
      ],
      "metadata": {
        "id": "lIbSB1MvoU0z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f'Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n')"
      ],
      "metadata": {
        "id": "MW-ceDLBoQMW"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The training process is conducted over several iterations (*epochs*). During each epoch, the model learns parameters to make better predictions."
      ],
      "metadata": {
        "id": "Tu4mLPxXpRpR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "for t in range(epochs):\n",
        "    print(f'Epoch {t+1}\\n-----------------------------')\n",
        "    train(train_dataloader, model, loss_fn, optimizer)\n",
        "    test(test_dataloader, model, loss_fn)\n",
        "print('Done!')"
      ],
      "metadata": {
        "id": "WkUNd3E5pOz_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1327d5dc-b03c-40f2-ea70-c06a43fdbeba"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-----------------------------\n",
            "loss: 2.304957 [    0/60000]\n",
            "loss: 2.298208 [ 6400/60000]\n",
            "loss: 2.278381 [12800/60000]\n",
            "loss: 2.267752 [19200/60000]\n",
            "loss: 2.253555 [25600/60000]\n",
            "loss: 2.223569 [32000/60000]\n",
            "loss: 2.227242 [38400/60000]\n",
            "loss: 2.191571 [44800/60000]\n",
            "loss: 2.202316 [51200/60000]\n",
            "loss: 2.155801 [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 41.6%, Avg loss: 2.159084 \n",
            "\n",
            "Epoch 2\n",
            "-----------------------------\n",
            "loss: 2.178761 [    0/60000]\n",
            "loss: 2.167630 [ 6400/60000]\n",
            "loss: 2.109200 [12800/60000]\n",
            "loss: 2.113581 [19200/60000]\n",
            "loss: 2.068051 [25600/60000]\n",
            "loss: 2.015587 [32000/60000]\n",
            "loss: 2.031248 [38400/60000]\n",
            "loss: 1.957217 [44800/60000]\n",
            "loss: 1.975772 [51200/60000]\n",
            "loss: 1.870401 [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 52.5%, Avg loss: 1.891362 \n",
            "\n",
            "Epoch 3\n",
            "-----------------------------\n",
            "loss: 1.943697 [    0/60000]\n",
            "loss: 1.906307 [ 6400/60000]\n",
            "loss: 1.794641 [12800/60000]\n",
            "loss: 1.811485 [19200/60000]\n",
            "loss: 1.710008 [25600/60000]\n",
            "loss: 1.678709 [32000/60000]\n",
            "loss: 1.674402 [38400/60000]\n",
            "loss: 1.589167 [44800/60000]\n",
            "loss: 1.625812 [51200/60000]\n",
            "loss: 1.486577 [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 58.2%, Avg loss: 1.527298 \n",
            "\n",
            "Epoch 4\n",
            "-----------------------------\n",
            "loss: 1.614202 [    0/60000]\n",
            "loss: 1.571185 [ 6400/60000]\n",
            "loss: 1.424678 [12800/60000]\n",
            "loss: 1.474904 [19200/60000]\n",
            "loss: 1.362000 [25600/60000]\n",
            "loss: 1.371745 [32000/60000]\n",
            "loss: 1.368295 [38400/60000]\n",
            "loss: 1.296840 [44800/60000]\n",
            "loss: 1.342010 [51200/60000]\n",
            "loss: 1.225666 [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 62.3%, Avg loss: 1.260549 \n",
            "\n",
            "Epoch 5\n",
            "-----------------------------\n",
            "loss: 1.349301 [    0/60000]\n",
            "loss: 1.327528 [ 6400/60000]\n",
            "loss: 1.159182 [12800/60000]\n",
            "loss: 1.256048 [19200/60000]\n",
            "loss: 1.133623 [25600/60000]\n",
            "loss: 1.164349 [32000/60000]\n",
            "loss: 1.178444 [38400/60000]\n",
            "loss: 1.112342 [44800/60000]\n",
            "loss: 1.162974 [51200/60000]\n",
            "loss: 1.067466 [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 64.5%, Avg loss: 1.093433 \n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Saving Models\n",
        "To save a model, we need to serialize the internal state dictionary (containing the model parameters)."
      ],
      "metadata": {
        "id": "D5giqnONtuyM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'model.pth')\n",
        "print('Saved PyTorch Model State to model.pth')"
      ],
      "metadata": {
        "id": "XxyUS92mpqOt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9d83c66-4493-4ea9-e673-0fc9e3cda2a2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved PyTorch Model State to model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Loading Models\n",
        "The process for loading a model includes re-creating the model structure and loading the state dictionary into it."
      ],
      "metadata": {
        "id": "NT7srmB1uX0g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork()\n",
        "model.load_state_dict(torch.load('model.pth'))"
      ],
      "metadata": {
        "id": "-DXHpgilufHd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f69c37cf-f6c6-4c7a-d74c-5eeb84c52139"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This model can be used to make predictions now:"
      ],
      "metadata": {
        "id": "RlHsYN2huoGL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classes = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "           'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
      ],
      "metadata": {
        "id": "4cmx6-KIuq9d"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "x, y = test_data[0][0], test_data[0][1]\n",
        "with torch.no_grad():\n",
        "    pred = model(x)\n",
        "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
      ],
      "metadata": {
        "id": "B4LgSvUau4mX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20f47ce3-5449-41a8-a59a-e0d5e39cc770"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TENSORS\n",
        "In PyTorch, tensors are used to encode the inputs and outputs of a model, as well as the model's parameters.\n",
        "\n",
        "Tensors are similar to NumPy's `ndarrays`, except that tensors can run on GPUs or other hardware accelerators. Tensors are also optimized for automatic differentiation."
      ],
      "metadata": {
        "id": "Xe0vTYOpwA6O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "T4DCmQWuvWKc"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Initializing a Tensor"
      ],
      "metadata": {
        "id": "TBYPeUmRxLuP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Directly from data"
      ],
      "metadata": {
        "id": "72KL7VwBxfu9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [[1,2], [3,4]]\n",
        "x_data = torch.tensor(data)\n",
        "x_data"
      ],
      "metadata": {
        "id": "KjD1oaqYxLXV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "649922d4-a8a1-4791-99fd-b0149c414f25"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2],\n",
              "        [3, 4]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* From a Numpy array"
      ],
      "metadata": {
        "id": "BVszFi7sxpNe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np_array = np.array(data)\n",
        "x_np = torch.from_numpy(np_array)\n",
        "x_np"
      ],
      "metadata": {
        "id": "z65OS0rXxoRQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3488f3ba-fcea-4303-cc69-7a92a0d849b1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2],\n",
              "        [3, 4]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* From another tensor"
      ],
      "metadata": {
        "id": "Dqhz9hiSxwts"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The new tensor retains the properties (shape, datatype) of the argument tensor, unless explicitly overridden."
      ],
      "metadata": {
        "id": "LLOw_-uSx8Jf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_ones = torch.ones_like(x_data) # retains the properties of x_data\n",
        "print(f'Ones Tensor: \\n {x_ones} \\n')"
      ],
      "metadata": {
        "id": "NGW3l5vRxv1u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0dcbd5f-ca48-4835-9e8d-e80ce4d788a9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ones Tensor: \n",
            " tensor([[1, 1],\n",
            "        [1, 1]]) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the dataype of x_data\n",
        "print(f'Random Tensor: \\n {x_rand} \\n')"
      ],
      "metadata": {
        "id": "Dk8BoUJpyLED",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "118bb79d-5818-47a6-e9e4-9512c3f4aeed"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Tensor: \n",
            " tensor([[0.8199, 0.6290],\n",
            "        [0.1636, 0.5197]]) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* With random or constant values"
      ],
      "metadata": {
        "id": "HaG1NXiYz5uY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`shape` is a tuple of tensor dimensions."
      ],
      "metadata": {
        "id": "-S4izYYh0AGl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shape = (2,3,)\n",
        "\n",
        "rand_tensor = torch.rand(shape)\n",
        "print(f'Random Tensor: \\n {rand_tensor} \\n')\n",
        "\n",
        "ones_tensor = torch.ones(shape)\n",
        "print(f'Ones Tensor: \\n {ones_tensor} \\n')\n",
        "\n",
        "zeros_tensor = torch.zeros(shape)\n",
        "print(f'Zeros Tensor: \\n {zeros_tensor}')"
      ],
      "metadata": {
        "id": "S6FkjmcJz1eH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a640194d-6dda-4c61-8238-e8119fb47910"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Tensor: \n",
            " tensor([[0.3476, 0.8023, 0.3224],\n",
            "        [0.4903, 0.5529, 0.4781]]) \n",
            "\n",
            "Ones Tensor: \n",
            " tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]]) \n",
            "\n",
            "Zeros Tensor: \n",
            " tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Attributes of a Tensor"
      ],
      "metadata": {
        "id": "dZIiUCXg0Yjc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.rand(3,4)\n",
        "\n",
        "print(f'Shape of tesor: {tensor.shape}')\n",
        "print(f'Datatype of tensor: {tensor.dtype}')\n",
        "print(f'Device tensor is stored on: {tensor.device}')"
      ],
      "metadata": {
        "id": "nXoOpBIt0XXg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f230b213-9d09-43f4-d2bf-df89af3bafb0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of tesor: torch.Size([3, 4])\n",
            "Datatype of tensor: torch.float32\n",
            "Device tensor is stored on: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Operations on Tensors\n",
        "By default, tensors are created on the CPU. We need to explicitly move tensors to the GPU using `.to` method (after checking for GPU availability). Keep in mind that copying large tensors across devices can be expensive in terms of time and memory!"
      ],
      "metadata": {
        "id": "0ThXLq0n0qSV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# move tensor to the GPU if available\n",
        "if torch.cuda.is_available():\n",
        "    tensor = tensor.to('cuda')"
      ],
      "metadata": {
        "id": "LI8nlf1h0pXa"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Standard numpy-like indexing and slicing"
      ],
      "metadata": {
        "id": "Afuj-rja1L1M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.ones(4,4)\n",
        "\n",
        "print('First row: ', tensor[0])\n",
        "print('First column: ', tensor[:,0])\n",
        "print('Last column: ', tensor[..., -1])\n",
        "\n",
        "tensor[:,1] = 0\n",
        "print(tensor)"
      ],
      "metadata": {
        "id": "8X4CGQy01PM0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "180bf26d-978d-48a5-d7a6-01c99e013176"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First row:  tensor([1., 1., 1., 1.])\n",
            "First column:  tensor([1., 1., 1., 1.])\n",
            "Last column:  tensor([1., 1., 1., 1.])\n",
            "tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Joining tensors"
      ],
      "metadata": {
        "id": "aPa7Z_5m1omo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`torch.cat` concatenates a sequence of tensors along a given dimension"
      ],
      "metadata": {
        "id": "2QLJ7hu-14tn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
        "print(t1)"
      ],
      "metadata": {
        "id": "vgLk1M681eHr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c61f4f6c-0a95-4eaf-b41e-266924d447bf"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`torch.stack` stacks a sequence of tensors along a given dimension"
      ],
      "metadata": {
        "id": "4Y7PdMJs19fF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t2 = torch.stack([tensor, tensor, tensor], dim=1)\n",
        "print(t2)"
      ],
      "metadata": {
        "id": "IUOD8EL-1u8w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5aa5178e-ed4d-48a0-deb1-5884eab55a49"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[1., 0., 1., 1.],\n",
            "         [1., 0., 1., 1.],\n",
            "         [1., 0., 1., 1.]],\n",
            "\n",
            "        [[1., 0., 1., 1.],\n",
            "         [1., 0., 1., 1.],\n",
            "         [1., 0., 1., 1.]],\n",
            "\n",
            "        [[1., 0., 1., 1.],\n",
            "         [1., 0., 1., 1.],\n",
            "         [1., 0., 1., 1.]],\n",
            "\n",
            "        [[1., 0., 1., 1.],\n",
            "         [1., 0., 1., 1.],\n",
            "         [1., 0., 1., 1.]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Arithmetic operations"
      ],
      "metadata": {
        "id": "YYXZsCF42I5T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This computes the matrix multiplication between two tensors\n",
        "# y1, y2, y3 will have the same value\n",
        "y1 = tensor @ tensor.T\n",
        "print(y1)"
      ],
      "metadata": {
        "id": "W5NAML5810nU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7665a2b9-d0b8-4cca-aea7-510706238ea7"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y2 = tensor.matmul(tensor.T)\n",
        "print(y2)"
      ],
      "metadata": {
        "id": "yZiOl7e42XIV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8a42f34-c535-4849-aa2f-76ddf1ea3152"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y3 = torch.rand_like(tensor)\n",
        "torch.matmul(tensor, tensor.T, out=y3)"
      ],
      "metadata": {
        "id": "3lLOnVIV2huQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68433def-3c08-4f1a-cf0a-c02bf87eb214"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[3., 3., 3., 3.],\n",
              "        [3., 3., 3., 3.],\n",
              "        [3., 3., 3., 3.],\n",
              "        [3., 3., 3., 3.]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This computes the element-wise product.\n",
        "# z1, z2, z3 will have the same value\n",
        "z1 = tensor * tensor\n",
        "print(z1)"
      ],
      "metadata": {
        "id": "GIBIVv5P2qxy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b9099b9-788e-4188-8cb3-e7f631952a71"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z2 = tensor.mul(tensor)\n",
        "print(z2)"
      ],
      "metadata": {
        "id": "SkwvKw2126ZV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54571d0b-080c-4651-d3ca-1d439284e9b5"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z3 = torch.rand_like(tensor)\n",
        "torch.mul(tensor, tensor, out=z3)"
      ],
      "metadata": {
        "id": "fEnyvuCx2-h3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03c61a08-6c13-4f03-a380-4eb174671451"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 1., 1.],\n",
              "        [1., 0., 1., 1.],\n",
              "        [1., 0., 1., 1.],\n",
              "        [1., 0., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Single-element tensors"
      ],
      "metadata": {
        "id": "BHkmlwTO3JSJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For a one-element tensor, for example by aggregating all values of a tensor into one value, we can convert it to a Python numerical value using `item()`"
      ],
      "metadata": {
        "id": "vVkn3hRv3LJ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agg = tensor.sum()\n",
        "agg_item = agg.item()\n",
        "print(agg, type(agg))\n",
        "print(agg_item, type(agg_item))"
      ],
      "metadata": {
        "id": "N87BiQV03EPe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36f612d7-7cc0-4216-c12e-219409e40365"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(12.) <class 'torch.Tensor'>\n",
            "12.0 <class 'float'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* In-place operations"
      ],
      "metadata": {
        "id": "2HRG9TsZ3bxO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Operations that store the result into the operand are called in-place. They are denoted by a `_` suffix"
      ],
      "metadata": {
        "id": "gd1W7qaz3iug"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(tensor, '\\n')\n",
        "tensor.add_(5)\n",
        "print(tensor)"
      ],
      "metadata": {
        "id": "R4V8erUX3Zv-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1629bbc6-5e41-43a8-e35b-dce807afa198"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]]) \n",
            "\n",
            "tensor([[6., 5., 6., 6.],\n",
            "        [6., 5., 6., 6.],\n",
            "        [6., 5., 6., 6.],\n",
            "        [6., 5., 6., 6.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Bridge with NumPy"
      ],
      "metadata": {
        "id": "UTqioezT30YP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Tensor to NumPy array"
      ],
      "metadata": {
        "id": "pcD2hCqt37NN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.ones(5)\n",
        "print(f't: {t}')\n",
        "n = t.numpy()\n",
        "print(f'n: {n}')"
      ],
      "metadata": {
        "id": "DnvwkFGY3ufy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20d516bf-daca-4f75-c836-aa4146a51a11"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t: tensor([1., 1., 1., 1., 1.])\n",
            "n: [1. 1. 1. 1. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A change in the tensor reflects in the NumPy array"
      ],
      "metadata": {
        "id": "PfOSBXys4Ik7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t.add_(1)\n",
        "print(f't: {t}')\n",
        "print(f'n: {n}')"
      ],
      "metadata": {
        "id": "ikSJz16f4G9q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e2afebf-da87-4759-b640-3ef9485ee32a"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t: tensor([2., 2., 2., 2., 2.])\n",
            "n: [2. 2. 2. 2. 2.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###NumPy array to Tensor"
      ],
      "metadata": {
        "id": "6qd8HPVm4RXr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = np.ones(5)\n",
        "t = torch.from_numpy(n)\n",
        "print(f'n: {n}')\n",
        "print(f't: {t}')"
      ],
      "metadata": {
        "id": "HLsbfsoK4PPv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b03fea15-700f-4335-8779-027abd2e4027"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n: [1. 1. 1. 1. 1.]\n",
            "t: tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Changes in the NumPy array reflects in the tensor"
      ],
      "metadata": {
        "id": "CZI7FluV4bwS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.add(n, 1, out=n)\n",
        "print(f'n: {n}')\n",
        "print(f't: {t}')"
      ],
      "metadata": {
        "id": "F_1U1a8e4a36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0d4230d-5aad-4979-cb7c-b80540cfb7d9"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n: [2. 2. 2. 2. 2.]\n",
            "t: tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#DATASETS & DATALOADERS\n",
        "`torch.utils.data.Dataset` stores the samples and their corresponding labels, and `torch.utils.data.DataLoader` wraps an iterable around the `Dataset` to enable easy access to the samples.\n",
        "\n",
        "PyTorch domain libraries provide a number of pre-loaded datasets (such as FashionMNIST) that subclass `torch.utils.data.Dataset` and implement functions specific to the particular data."
      ],
      "metadata": {
        "id": "_GOT7azq4oLG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The FashionMNIST Dataset has the following parameters:\n",
        "* `root` is the path where the train/test data is stored,\n",
        "* `train` specifies training or test dataset,\n",
        "* `download=True` downloads the data from the internet if it is not available at `root`,\n",
        "* `transform` and `target_transform` specify the feature and label transformations"
      ],
      "metadata": {
        "id": "BMPwWZrD5bFK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "KDiIkznY4l68"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = datasets.FashionMNIST(\n",
        "    root='data',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root='data',\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")"
      ],
      "metadata": {
        "id": "AyxhSOd36DDo"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Iterating and Visualizing the Dataset\n",
        "We can index `Datasets` manually like a list: `training_data[index]`. Use `matplotlib` to visualize some samples in the training data"
      ],
      "metadata": {
        "id": "dcFxpqHz6SRt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels_map = {\n",
        "    0: 'T-Shirt',\n",
        "    1: 'Trouser',\n",
        "    2: 'Pullover',\n",
        "    3: 'Dress',\n",
        "    4: 'Coat',\n",
        "    5: 'Sandal',\n",
        "    6: 'Shirt',\n",
        "    7: 'Sneaker',\n",
        "    8: 'Bag',\n",
        "    9: 'Ankle Boot'\n",
        "}\n",
        "\n",
        "figure = plt.figure(figsize=(8,8))\n",
        "cols, rows = 3,3\n",
        "for i in range(1, cols * rows + 1):\n",
        "    sample_idx = torch.randint(len(training_data),\n",
        "                               size=(1,)).item()\n",
        "    img, label = training_data[sample_idx]\n",
        "\n",
        "    figure.add_subplot(rows, cols, i)\n",
        "    plt.title(labels_map[label])\n",
        "    plt.axis('off')\n",
        "    plt.imshow(img.squeeze(), cmap='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3hah1Dhi6QZw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "outputId": "95c3cc3f-a193-4816-9a3d-bde71b56a74e"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 9 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Creating a Custom Dataset for your files\n",
        "A custom Dataset class must implement three functions: `__init__`, `__len__`, and `__getitem__`."
      ],
      "metadata": {
        "id": "lZlQQ6Ga7WqU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the FahsionMNIST images are stored in a direction `img_dir`, and their labels are stored separately in a CSV file `annotations_file`."
      ],
      "metadata": {
        "id": "Aq7ijtLt7m_p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from torchvision.io import read_image"
      ],
      "metadata": {
        "id": "nbfnnkkj7S7I"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
        "        self.img_labels = pd.read_csv(annotations_file)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem(self, idx):\n",
        "        img_path = os.path.join(self.img_dir,\n",
        "                                self.img_labels.iloc[idx, 0])\n",
        "        image = read_image(img_path)\n",
        "        label = self.img_labels.iloc[idx, 1]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "BHRnxxvY74bG"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###`__init__`\n",
        "The `__init__` function is run once when instantiating the Dataset object. We initialize the directory containing the images, the annotations file, and both transforms.\n",
        "\n",
        "The labels.csv file looks like:\n",
        "```\n",
        "tshirt1.jpg, 0\n",
        "tshirt2.jpg, 0\n",
        "......\n",
        "ankleboot999.jpy, 9\n",
        "```"
      ],
      "metadata": {
        "id": "57moNUgA8wfk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
        "    self.img_labels = pd.read_csv(annotations_file, \n",
        "                                  names=['file_name', 'label'])\n",
        "    self.img_dir = img_dir\n",
        "    self.transform = transform\n",
        "    self.target_transform = target_transform"
      ],
      "metadata": {
        "id": "YRp0RuGD9gzt"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###`__len__`\n",
        "the number of samples in the dataset"
      ],
      "metadata": {
        "id": "MHD-K7kX98XF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def __len__(self):\n",
        "    return len(self.img_labels)"
      ],
      "metadata": {
        "id": "6VTpfYqy-AYz"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###`__getitem__`\n",
        "The `__getitem__` function loads and returns a sample from the dataset at the given index `idx`.\n",
        "\n",
        "Based on the index, it identifies the image's location on disk, converts that to a tensor using `read_image`, retrieves the corresponding label from the csv data in `self.img_labels`, calls the transform function on them (if applicable), and returns the tensor image and corresponding label in a tuple."
      ],
      "metadata": {
        "id": "mGv9Ran4-Drj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def __getitem__(self, idx):\n",
        "    img_path = os.path_join(self.img_dir,\n",
        "                            self.img_labels.iloc[idx,0])\n",
        "    image = read_image(img_path)\n",
        "    label = self.img_labels.iloc[idx, 1]\n",
        "\n",
        "    if self.transform:\n",
        "        image = self.transform(image)\n",
        "    if self.target_transform:\n",
        "        label = self.target_transform(label)\n",
        "    return image, label"
      ],
      "metadata": {
        "id": "5TBrebbs-6oX"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Preparing your data fro training with DataLoaders\n",
        "The `Dataset` retrieves dataset's features and labels on sample at a time. While training a model, we typically want to pass samples in \"minibatches\", reshuffle the data at every epoch to reduce model overfitting, and use Python's `multiprocessing` to speed up data retrieval.\n",
        "\n",
        "`DataLoader` is an iterable that abstracts this complexity:"
      ],
      "metadata": {
        "id": "kjTk9uB3_UpF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "XnKlYKfR_uKJ"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(training_data, \n",
        "                              batch_size=64,\n",
        "                              shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataloader,\n",
        "                             batch_size=64,\n",
        "                             shuffle=True)"
      ],
      "metadata": {
        "id": "cBnwYpPx_wak"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Iterate through the DataLoader\n",
        "After loading the dataset into the `DataLoader`, we can iterate through the dataset as needed. Each iteration below returns a batch of `train_features` and `train_labels` (containing `batch_size=64` features and labels, respectively). `shuffle=True` means the data will be shuffled after we iterate all batches."
      ],
      "metadata": {
        "id": "hKm0SNhc_-EZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display image and label\n",
        "train_features, train_labels = next(iter(train_dataloader))\n",
        "print(f'Feature batch shape: {train_features.size()}')\n",
        "print(f'Labels batch shape: {train_labels.size()}')\n",
        "\n",
        "img = train_features[0].squeeze()\n",
        "label = train_labels[0]\n",
        "plt.imshow(img, cmap='gray')\n",
        "plt.show()\n",
        "print(f'Label: {label}')"
      ],
      "metadata": {
        "id": "U6k4tbE-_9mb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "outputId": "f713569c-46c2-4b52-8932-72805e5e01b6"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature batch shape: torch.Size([64, 1, 28, 28])\n",
            "Labels batch shape: torch.Size([64])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label: 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_features[0].shape, train_features[0].squeeze().shape"
      ],
      "metadata": {
        "id": "tjUN810DA1jD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc96668c-876b-4d58-dec1-9447eefee0a9"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 28, 28]), torch.Size([28, 28]))"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TRANSFORMS\n",
        "The transforms are used to perform some manipulation of the data and make it suitable for training"
      ],
      "metadata": {
        "id": "pwhLM7gvBN0l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "All TorchVision datasets have two parameters - `transform` to modify the features and `target_transform` to modify the labels - that accept callables containing the transformation logic. The `torchvision.transforms` module offers several commony-used transforms out of the box.\n",
        "\n",
        "The FahsionMNIST features are in PIL image format, and the labels are integers. For training, we need the features as normalized tensors, and the labels as one-hot encoded tensors. To make these transformations, we use `ToTensor` and `Lambda`."
      ],
      "metadata": {
        "id": "TBT5IY2VD_Ny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Lambda"
      ],
      "metadata": {
        "id": "IarL368SA-Vu"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds = datasets.FashionMNIST(\n",
        "    root='data',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        "    target_transform=Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))\n",
        ")"
      ],
      "metadata": {
        "id": "IVhx1ARSElVS"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##`ToTensor()`\n",
        "`ToTensor` convets a PIL image or NumPy `ndarray` into a `FloatTensor`. and scales the image's pixel intensity values in the range [0., 1.]."
      ],
      "metadata": {
        "id": "F5jUgNPuE8CB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##`Lambda` Transforms\n",
        "Lambda transforms apply any user-defined lambda function.\n",
        "\n",
        "Here, this lambda function turns the integer into a one-hot encoded tensor. It first creates a zero tensor of size 10 (the number of labels in the dataset) and calls `scatter_` which assigns a `value=1` on the index as given by the label `y`."
      ],
      "metadata": {
        "id": "Qx5zb1aFIkfj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target_transform=Lambda(lambda y: torch.zeros(10, \n",
        "                                              dtype=torch.float).scatter_(dim=0, \n",
        "                                                                         index=torch.tensor(y), value=1))"
      ],
      "metadata": {
        "id": "Dld20Lc1E6GB"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#BUILD THE NEURAL NETWORK\n",
        "The `torch.nn` namespace provides all the building blocks we need to build neural network. Every module in PyTorch subclasses the `nn.Module`. A neutral network is a module itself that consists of other modules (layers). This nested structure allows for building and managing complex architecturs easily."
      ],
      "metadata": {
        "id": "d_mxIsnWJKrx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following sections are used to build a neural network to classify images in the FashionMNIST dataset."
      ],
      "metadata": {
        "id": "-6bZeox-qI3r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms"
      ],
      "metadata": {
        "id": "t37W_lKDJNdp"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Get Device for Training"
      ],
      "metadata": {
        "id": "oJD1PIMzqYp0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'Using {device} device')"
      ],
      "metadata": {
        "id": "hjJL9th9qYGr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9de69987-8eb8-42d3-b48e-bafdaeb90166"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Define the Class\n",
        "We define neural networks by subclassing `nn.Module`, and initialize the neural network layers in `__init__`. Every `nn.Module` subclass implements the operations on input data in the `forward` method."
      ],
      "metadata": {
        "id": "XVN4begEqkR2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "68kcVMcfrdRC"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can create an instance of `NeuralNetwork`, and move it to the `device`, and print its structure"
      ],
      "metadata": {
        "id": "1A5iAXKOsAcD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "id": "SV2QBPxgr8Jw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fd888be-2b3f-4111-bdf7-903e035fd7ef"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To use this model, we pass it the input data. This executes the model's `forward`, along with some background operations. Do NOT call `model.forward()` directly!\n",
        "\n",
        "Calling the model on the input returns a 10-dimensional tensor with raw predicted values for each class. We get the prediction probabilities by passing it through an instance of the `nn.Softmax` module."
      ],
      "metadata": {
        "id": "FEG-L3lfsKuq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.rand(1, 28, 28, device=device)\n",
        "logits = model(X)\n",
        "pred_probab = nn.Softmax(dim=1)(logits)\n",
        "y_pred = pred_probab.argmax(1)\n",
        "print(f'Predicted class: {y_pred}')"
      ],
      "metadata": {
        "id": "CC_4-nZ5sJSo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "652f1833-c4f5-4a32-b1b0-484daafc8013"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: tensor([5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model Layers\n",
        "Sampling a minibatch of 3 images of size 28x28 and passing it through the network"
      ],
      "metadata": {
        "id": "nl5okyw3ttQS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_image = torch.rand(3, 28, 28)\n",
        "print(input_image.size())"
      ],
      "metadata": {
        "id": "MFhr7r30tma6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae03253f-92c5-45d1-92dc-78f39d173606"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###`nn.Flatten`\n",
        "We initialize the `nn.Flatten` layer to convert each 2D 28x28 image into a contiguous array of 784 pixel values (the minibatch diemnsion (at `dim=0` is maintained)."
      ],
      "metadata": {
        "id": "_aDmGAY9t_8b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "flatten = nn.Flatten()\n",
        "flat_image = flatten(input_image)\n",
        "print(flat_image.size())"
      ],
      "metadata": {
        "id": "3fdFAX7zt_V5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f53d8ad6-f669-4fd9-f37a-f9e24afe1b17"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 784])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###`nn.Linear`\n",
        "The linear layer is a module that applies a linear transformation on the input using its stored weights and biases"
      ],
      "metadata": {
        "id": "Td7CX6uiuTJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layer1 = nn.Linear(in_features=28*28, out_features=20)\n",
        "hidden1 = layer1(flat_image)\n",
        "print(hidden1.size())"
      ],
      "metadata": {
        "id": "McG1Mrr8uSbv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b83810e-0c6f-4503-a711-a567dc686555"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 20])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###`nn.ReLU`\n",
        "Non-linear activations are what create the complex mappings between the model's inputs and outputs. They are applied after linear transformations to introduce *nonlinearity*, helping neural networks learn a wide variety of phenomena.\n",
        "\n",
        "In this model, we use `nn.ReLU` between linear layers, but there is other activations to introduce non-linearity as well."
      ],
      "metadata": {
        "id": "wdmVT9URvpds"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Before ReLU: {hidden1}\\n\\n')\n",
        "hidden1 = nn.ReLU()(hidden1)\n",
        "print(f'After ReLU: {hidden1}')"
      ],
      "metadata": {
        "id": "XRSEl9QqvU8K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85079ea0-4237-49d0-ad05-73912d91db14"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before ReLU: tensor([[ 0.7889,  0.5328, -0.0018, -0.1216, -0.1747, -0.3829, -0.0358,  0.4350,\n",
            "          0.1056, -0.2802,  0.2850,  0.3303,  0.0785, -0.1400, -0.6018, -0.1225,\n",
            "         -0.4183,  0.7909, -0.2178, -0.1577],\n",
            "        [ 0.7021,  0.5299,  0.2109, -0.0539, -0.0485, -0.1843,  0.0015,  0.0556,\n",
            "          0.1155, -0.2586,  0.4357,  0.1028, -0.2441, -0.3793, -0.5860, -0.5061,\n",
            "         -0.3492,  0.6666,  0.0959,  0.0218],\n",
            "        [ 0.4748,  0.7957, -0.0946, -0.0292, -0.0210, -0.2094,  0.2138,  0.4016,\n",
            "         -0.2211, -0.6329,  0.3566,  0.1418,  0.0900,  0.1151, -0.5289, -0.2583,\n",
            "         -0.3503,  0.8979, -0.1011,  0.0794]], grad_fn=<AddmmBackward0>)\n",
            "\n",
            "\n",
            "After ReLU: tensor([[0.7889, 0.5328, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4350, 0.1056,\n",
            "         0.0000, 0.2850, 0.3303, 0.0785, 0.0000, 0.0000, 0.0000, 0.0000, 0.7909,\n",
            "         0.0000, 0.0000],\n",
            "        [0.7021, 0.5299, 0.2109, 0.0000, 0.0000, 0.0000, 0.0015, 0.0556, 0.1155,\n",
            "         0.0000, 0.4357, 0.1028, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6666,\n",
            "         0.0959, 0.0218],\n",
            "        [0.4748, 0.7957, 0.0000, 0.0000, 0.0000, 0.0000, 0.2138, 0.4016, 0.0000,\n",
            "         0.0000, 0.3566, 0.1418, 0.0900, 0.1151, 0.0000, 0.0000, 0.0000, 0.8979,\n",
            "         0.0000, 0.0794]], grad_fn=<ReluBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###`nn.Sequential`\n",
        "`nn.Sequential` is an ordered container of modules. The data is passed through all the modules in the same order as defined."
      ],
      "metadata": {
        "id": "DT7NT8-pwtpe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seq_modules = nn.Sequential(\n",
        "    flatten,\n",
        "    layer1,\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(20,10)\n",
        ")\n",
        "input_image = torch.rand(3,28,28)\n",
        "logits = seq_modules(input_image)"
      ],
      "metadata": {
        "id": "ajqTJdQawg1I"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###`nn.Softmax`\n",
        "The returned logits above contain raw values in [-infty, infty]. As we pass it through the `nn.Softmax` module, the logits are scaled to values [0,1] representing the model's predicted probabilities for each class. `dim` parameter indicates the dimension along which the values must sum to 1."
      ],
      "metadata": {
        "id": "GFbpm8XcyMFq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "softmax = nn.Softmax(dim=1)\n",
        "pred_probab = softmax(logits)"
      ],
      "metadata": {
        "id": "-EjBLRRQzC2T"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model Parameters\n",
        "Many layers inside a neural network are *parameterized*, i.e. have associated weights and biases that are optimized during training. Subclassing `nn.Module` automatically tracks all fields defined inside the model object, and makes all parameters accessible using the model's `parameters()` or `named_parameters()` methods.\n",
        "\n",
        "In this example, we iterate over each parameter, and print its size and a preview of its valus:"
      ],
      "metadata": {
        "id": "RygkeVf9zGgM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Model structure: ', model, '\\n\\n')\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "    print(f'Layer: {name} | Size: {param.size()} | Values: {param[:2]} \\n')"
      ],
      "metadata": {
        "id": "Lg1ZSYo6zhfs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95a82242-7640-4c3e-e873-81bf6230c1db"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model structure:  NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ") \n",
            "\n",
            "\n",
            "Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values: tensor([[ 0.0146, -0.0324,  0.0331,  ...,  0.0193, -0.0010,  0.0135],\n",
            "        [ 0.0097,  0.0271, -0.0267,  ...,  0.0104, -0.0355, -0.0243]],\n",
            "       grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values: tensor([-0.0049,  0.0293], grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values: tensor([[ 0.0425,  0.0057, -0.0049,  ...,  0.0215, -0.0210,  0.0344],\n",
            "        [-0.0002,  0.0283,  0.0427,  ...,  0.0087, -0.0025, -0.0117]],\n",
            "       grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values: tensor([ 0.0313, -0.0266], grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values: tensor([[-0.0322, -0.0220,  0.0245,  ..., -0.0297,  0.0346,  0.0434],\n",
            "        [-0.0029,  0.0181, -0.0370,  ...,  0.0396, -0.0077, -0.0308]],\n",
            "       grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values: tensor([0.0007, 0.0145], grad_fn=<SliceBackward0>) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#AUTOMATIC DIFFERENTIATION WITH `TORCH.AUTOGRAD`"
      ],
      "metadata": {
        "id": "tYnSeUWIz3fP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the backpropagation, parameters (model weights) are adjusted according to the **gradient** of the loss function with respect to the given parameter.\n",
        "\n",
        "To compute those gradients, PyTorch has a built-in differentiation engine called `torch.autograd`. It supports automatic computation of gradient for any computational graph.\n",
        "\n",
        "Consider the simplest one-layer neural network, with input `x`, parameters `w` and `b`, and some loss function."
      ],
      "metadata": {
        "id": "Zm2agMBiz7zm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "x = torch.ones(5) # input tensor\n",
        "y = torch.zeros(3) # expected output\n",
        "w = torch.randn(5, 3, requires_grad=True)\n",
        "b = torch.randn(3, requires_grad=True)\n",
        "z = torch.matmul(x, w) + b\n",
        "loss = torch.nn.functional.binary_cross_entropy_with_logits(z, y)"
      ],
      "metadata": {
        "id": "SZzscwqM0lQb"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this network, `w` and `b` are parameters, which we need to optimize. Thus, we need to be able to compute the gradients of loss function with respect to those variables. In order to do that, we set the `requires_grad` property of those tensors.\n",
        "\n",
        "You can set the value of `requires_grad` when creating a tensor, or later by using `x.requires_grad_(True)` method."
      ],
      "metadata": {
        "id": "zbpagKMg1BjX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A function that we apply to tensors to construct computational graph is... in fact... an object of class `Function`. This object knows how to compute the function in the *forward* direction, and also now to compute its derivative during the *backward propagation* step. A reference to the backward propagation function is stored in `grad_fn` property of a tensor."
      ],
      "metadata": {
        "id": "Eul7kU7m2A_P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Gradient function for z =', z.grad_fn)\n",
        "print('Gradient function for loss =', loss.grad_fn)"
      ],
      "metadata": {
        "id": "w9s3pwJK07yC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bfc35c5-7e33-4a49-bd5f-498311ee8336"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient function for z = <AddBackward0 object at 0x7f7afedc59d0>\n",
            "Gradient function for loss = <BinaryCrossEntropyWithLogitsBackward0 object at 0x7f7afdd76150>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Computing Gradients\n",
        "To optimize weights of parameters in the neural network, we need to compute the derivatives of the loss function with respect to parameters. To compute those derivatives, we call `loss.backward()`, and then retrieve the values from `w.grad` and `b.grad`:"
      ],
      "metadata": {
        "id": "yN_1TLIi2j-0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss.backward()\n",
        "print(w.grad)\n",
        "print(b.grad)"
      ],
      "metadata": {
        "id": "5VCMexIK2hIQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02178ded-00b2-4002-bbc1-d36c9e8a6e00"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0110, 0.3264, 0.2503],\n",
            "        [0.0110, 0.3264, 0.2503],\n",
            "        [0.0110, 0.3264, 0.2503],\n",
            "        [0.0110, 0.3264, 0.2503],\n",
            "        [0.0110, 0.3264, 0.2503]])\n",
            "tensor([0.0110, 0.3264, 0.2503])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* We can only obtain the `grad` properties for the leaf nodes of the computational graph, which have `requires_grad` property set to `True`. For all other nodes in the graph, gradients will not be available.\n",
        "* We can only perform gradient calculations using `backward` once on a given graph, for performance reasons. If we need to do several `backward` calls on the same graph, we need to pass `retain_graph=True` to the `backward` call."
      ],
      "metadata": {
        "id": "WLKnJ3cz3CTb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Disabling Gradient Tracking\n",
        "By default, all tensors with `requires_grad=True` are tracking their computational history and support gradient computation.\n",
        "\n",
        "There are some cases when we do not need to do that, for example, when we have trained the model and just want to apply it to some input data, i.e. we only want to do `forward` computation through the network. We can stop tracking computations by surrounding the computation code with `torch.no_grad()` block:"
      ],
      "metadata": {
        "id": "e84e2rGe3v2y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z = torch.matmul(x, w) + b\n",
        "print(z.requires_grad)\n",
        "\n",
        "with torch.no_grad():\n",
        "    z = torch.matmul(x, w) + b\n",
        "print(z.requires_grad)"
      ],
      "metadata": {
        "id": "fPBlXCja2-Hk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cf977ae-23c3-485c-eece-f1fd615c776f"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another way to achieve the same result is to use the `detach()` method on the tensor:"
      ],
      "metadata": {
        "id": "TddBrJVP4fXI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z = torch.matmul(x, w) + b\n",
        "z_det = z.detach()\n",
        "print(z_det.requires_grad)"
      ],
      "metadata": {
        "id": "Cm4_DAE94c2q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81d0c4aa-8685-453b-dbaf-2bb8fe9d5c80"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reasons we may want to disable gradient tracking:\n",
        "* To mark some parameters in neural network as **frozen parameters**. This is a very common scenario for finetuning a pretrained network\n",
        "* To speed up computation when we are only doing forward pass, because computation on tensors that do not track gradients would be more efficient."
      ],
      "metadata": {
        "id": "QDKVq4fb4tjO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###More on Computational Graphs\n",
        "Autograd keeps a record of data (tensors) and all executed operations (along with the resulting new tensors) in a directed acyclic graph (DAG) consisting of `Function` objects. In this DAG, leaves are the input tensors, roots are the output tensors. By tracing this graph from roots to leaves, we can automatically compute the gradients using the chain rule.\n",
        "\n",
        "In a `forward` pass, autograd does two things simultaneously:\n",
        "* run the requested operation to compute a resulting tensor\n",
        "* maintain the operation's gradient function in the DAG\n",
        "\n",
        "The `backward` pass kicks off when `.backward()` is called on the DAG root. `autograd` then:\n",
        "* computes the gradients from each `.grad_fn`,\n",
        "* accumulates them in the respective tensor's `.grad` attribute,\n",
        "* propagates all the way to theleaf tensors using the chain rule."
      ],
      "metadata": {
        "id": "QBGkjo9t5Q0P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The graph is recreated from scratch, after each `.backward()` call, autograd starts populating a new graph. This is exactly what allows us to use control flow statements in the model, we can change the shape, size and operations at every iteration if needed."
      ],
      "metadata": {
        "id": "eOTDdXHH6WYU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#OPTIMIZING MODEL PARAMETERS\n"
      ],
      "metadata": {
        "id": "I2CzhDgK7Hee"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training a model is an iterative process; in each iteration (called an epoch) the model makes a guess about the output, calculates the error in its guess (loss), collects the derivatives of the error with respect to its parameters, and **optimizes** these parameters using gradient descent."
      ],
      "metadata": {
        "id": "YdLErWoT7J_W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Prerequisite Code"
      ],
      "metadata": {
        "id": "Mgg69waM7ftK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Lambda"
      ],
      "metadata": {
        "id": "KtAZz1504qlc"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = datasets.FashionMNIST(\n",
        "    root='data',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root='data',\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size=64)\n",
        "test_dataloader = DataLoader(test_data, batch_size=64)"
      ],
      "metadata": {
        "id": "kVNRI1_37lZI"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "model = NeuralNetwork()"
      ],
      "metadata": {
        "id": "woWgYy3K78Ej"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Hyperparameters\n",
        "Hyperparameters are adjustable parameters that let us control the model optimization process."
      ],
      "metadata": {
        "id": "Db1UjLXu8Lgi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We define the following hyperparameters for training:\n",
        "* **Number of Epochs** - the number times to iterate over the dataset\n",
        "* **Batch Size** - the number of data samples propagated through the network before the parameters are updated\n",
        "* **Learning Rate** - how much to update models parameters at each batch/epoch. Smaller values yield slow learning speed, while large values may result in unpredictable behavior during training."
      ],
      "metadata": {
        "id": "sm_ZUcr9k1ah"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 1e-3\n",
        "batch_size = 64\n",
        "epochs = 5"
      ],
      "metadata": {
        "id": "OY2C6PWu8J3r"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Optimization Loop\n",
        "Each epoch consists of two main parts:\n",
        "* **Train Loop** - iterate over the training dataset and try to converge to optimal parameters\n",
        "* **Validation/Test Loop** - iterate over the test dataset to check if model performance is improving "
      ],
      "metadata": {
        "id": "vkFQ1HjUlyJA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Loss Function\n",
        "**Loss function** measures the degree of dissimlarity of obtained result to the target value, and it is the loss function that we want to minimize during training."
      ],
      "metadata": {
        "id": "QoqDYU1nmamC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Common loss functions include `nn.MSELoss` (Mean Square Error) for regression tasks, and `nn.NLLLoss` (Negative Log Likelihood) for classification. `nn.CrossEntropyLoss` combines `nn.LogSoftmax` and `nn.NLLLoss`."
      ],
      "metadata": {
        "id": "sDarFOqxnBXO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Optimizer\n",
        "**Optimization algorithms** define how the training process is performed. All optimization logic is encapsulated in the `optimizer` object."
      ],
      "metadata": {
        "id": "nq9kZccUnVDI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We initialize the optimizer by registering the model's parameters that need to be trained, and passing in the learning rate hyperparameter."
      ],
      "metadata": {
        "id": "NJh4wifDnnZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "maB7VKL1nvuj"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inside the training loop, optimization happens in three steps:\n",
        "* Call `optimizer.zero_grad()` to reset the gradients of model parameters. Gradients by default add up; to prevent double-counting, we expilictly zero them at each iteration.\n",
        "* Backpropagate the prediction loss with a call to `loss.backward()`.\n",
        "* Once having gradients, we call `optimizer.step()` to adjust the parameters by the gradients collected in the backward pass."
      ],
      "metadata": {
        "id": "nlj7MoVTn0N5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Full Implementation"
      ],
      "metadata": {
        "id": "tCDgD15ponfX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        # Compute prediction and loss\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f'loss: {loss:>7f} [{current:>5d}/{size:>5d}]')\n",
        "\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0,0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f'Test Error: \\n Accuracy: {(100*correct):0.1f}%, Avg loss: {test_loss:>8f} \\n')"
      ],
      "metadata": {
        "id": "40GBA89aop4O"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We initialize the loss function and optimizer, and pass it to `train_loop` and `test_loop`."
      ],
      "metadata": {
        "id": "XJvRQoE9rMLB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "epochs = 10\n",
        "for i in range(epochs):\n",
        "    print(f'Epoch {t+1}\\n--------------------------')\n",
        "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
        "    test_loop(test_dataloader, model, loss_fn)\n",
        "print('Done!')"
      ],
      "metadata": {
        "id": "-VBEhSparLoG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "108a5a04-a4b0-4575-ce9d-7c0affef953d"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch tensor([3., 3., 3., 3., 3.], dtype=torch.float64)\n",
            "--------------------------\n",
            "loss: 2.301264 [    0/60000]\n",
            "loss: 2.286018 [ 6400/60000]\n",
            "loss: 2.262222 [12800/60000]\n",
            "loss: 2.261820 [19200/60000]\n",
            "loss: 2.247670 [25600/60000]\n",
            "loss: 2.213701 [32000/60000]\n",
            "loss: 2.227579 [38400/60000]\n",
            "loss: 2.194950 [44800/60000]\n",
            "loss: 2.178491 [51200/60000]\n",
            "loss: 2.154064 [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 40.3%, Avg loss: 2.149404 \n",
            "\n",
            "Epoch tensor([3., 3., 3., 3., 3.], dtype=torch.float64)\n",
            "--------------------------\n",
            "loss: 2.160049 [    0/60000]\n",
            "loss: 2.146698 [ 6400/60000]\n",
            "loss: 2.085106 [12800/60000]\n",
            "loss: 2.109373 [19200/60000]\n",
            "loss: 2.062184 [25600/60000]\n",
            "loss: 1.985796 [32000/60000]\n",
            "loss: 2.032762 [38400/60000]\n",
            "loss: 1.950111 [44800/60000]\n",
            "loss: 1.943331 [51200/60000]\n",
            "loss: 1.881023 [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 56.9%, Avg loss: 1.879669 \n",
            "\n",
            "Epoch tensor([3., 3., 3., 3., 3.], dtype=torch.float64)\n",
            "--------------------------\n",
            "loss: 1.908293 [    0/60000]\n",
            "loss: 1.875548 [ 6400/60000]\n",
            "loss: 1.758791 [12800/60000]\n",
            "loss: 1.813735 [19200/60000]\n",
            "loss: 1.702356 [25600/60000]\n",
            "loss: 1.636006 [32000/60000]\n",
            "loss: 1.676840 [38400/60000]\n",
            "loss: 1.573540 [44800/60000]\n",
            "loss: 1.589237 [51200/60000]\n",
            "loss: 1.491804 [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 63.8%, Avg loss: 1.509500 \n",
            "\n",
            "Epoch tensor([3., 3., 3., 3., 3.], dtype=torch.float64)\n",
            "--------------------------\n",
            "loss: 1.570386 [    0/60000]\n",
            "loss: 1.533591 [ 6400/60000]\n",
            "loss: 1.382948 [12800/60000]\n",
            "loss: 1.470616 [19200/60000]\n",
            "loss: 1.346454 [25600/60000]\n",
            "loss: 1.326858 [32000/60000]\n",
            "loss: 1.355715 [38400/60000]\n",
            "loss: 1.278039 [44800/60000]\n",
            "loss: 1.307906 [51200/60000]\n",
            "loss: 1.214636 [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 64.6%, Avg loss: 1.240184 \n",
            "\n",
            "Epoch tensor([3., 3., 3., 3., 3.], dtype=torch.float64)\n",
            "--------------------------\n",
            "loss: 1.314083 [    0/60000]\n",
            "loss: 1.295529 [ 6400/60000]\n",
            "loss: 1.127803 [12800/60000]\n",
            "loss: 1.246474 [19200/60000]\n",
            "loss: 1.117306 [25600/60000]\n",
            "loss: 1.126860 [32000/60000]\n",
            "loss: 1.160060 [38400/60000]\n",
            "loss: 1.097228 [44800/60000]\n",
            "loss: 1.132851 [51200/60000]\n",
            "loss: 1.056589 [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 65.4%, Avg loss: 1.075423 \n",
            "\n",
            "Epoch tensor([3., 3., 3., 3., 3.], dtype=torch.float64)\n",
            "--------------------------\n",
            "loss: 1.144713 [    0/60000]\n",
            "loss: 1.148423 [ 6400/60000]\n",
            "loss: 0.963040 [12800/60000]\n",
            "loss: 1.108201 [19200/60000]\n",
            "loss: 0.978968 [25600/60000]\n",
            "loss: 0.995124 [32000/60000]\n",
            "loss: 1.041744 [38400/60000]\n",
            "loss: 0.984009 [44800/60000]\n",
            "loss: 1.020187 [51200/60000]\n",
            "loss: 0.960584 [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 66.3%, Avg loss: 0.971105 \n",
            "\n",
            "Epoch tensor([3., 3., 3., 3., 3.], dtype=torch.float64)\n",
            "--------------------------\n",
            "loss: 1.028282 [    0/60000]\n",
            "loss: 1.054736 [ 6400/60000]\n",
            "loss: 0.852089 [12800/60000]\n",
            "loss: 1.016629 [19200/60000]\n",
            "loss: 0.892586 [25600/60000]\n",
            "loss: 0.903821 [32000/60000]\n",
            "loss: 0.965322 [38400/60000]\n",
            "loss: 0.910221 [44800/60000]\n",
            "loss: 0.942683 [51200/60000]\n",
            "loss: 0.897245 [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 67.6%, Avg loss: 0.900688 \n",
            "\n",
            "Epoch tensor([3., 3., 3., 3., 3.], dtype=torch.float64)\n",
            "--------------------------\n",
            "loss: 0.943144 [    0/60000]\n",
            "loss: 0.990046 [ 6400/60000]\n",
            "loss: 0.772585 [12800/60000]\n",
            "loss: 0.952059 [19200/60000]\n",
            "loss: 0.835138 [25600/60000]\n",
            "loss: 0.838323 [32000/60000]\n",
            "loss: 0.911778 [38400/60000]\n",
            "loss: 0.860821 [44800/60000]\n",
            "loss: 0.887229 [51200/60000]\n",
            "loss: 0.851440 [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 68.7%, Avg loss: 0.850322 \n",
            "\n",
            "Epoch tensor([3., 3., 3., 3., 3.], dtype=torch.float64)\n",
            "--------------------------\n",
            "loss: 0.877809 [    0/60000]\n",
            "loss: 0.941450 [ 6400/60000]\n",
            "loss: 0.713116 [12800/60000]\n",
            "loss: 0.903909 [19200/60000]\n",
            "loss: 0.794218 [25600/60000]\n",
            "loss: 0.789825 [32000/60000]\n",
            "loss: 0.871348 [38400/60000]\n",
            "loss: 0.826326 [44800/60000]\n",
            "loss: 0.845913 [51200/60000]\n",
            "loss: 0.816116 [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 69.8%, Avg loss: 0.812224 \n",
            "\n",
            "Epoch tensor([3., 3., 3., 3., 3.], dtype=torch.float64)\n",
            "--------------------------\n",
            "loss: 0.825661 [    0/60000]\n",
            "loss: 0.902191 [ 6400/60000]\n",
            "loss: 0.666913 [12800/60000]\n",
            "loss: 0.866505 [19200/60000]\n",
            "loss: 0.763420 [25600/60000]\n",
            "loss: 0.753026 [32000/60000]\n",
            "loss: 0.838525 [38400/60000]\n",
            "loss: 0.800880 [44800/60000]\n",
            "loss: 0.813896 [51200/60000]\n",
            "loss: 0.787316 [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 71.1%, Avg loss: 0.781875 \n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SAVE AND LOAD THE MODEL"
      ],
      "metadata": {
        "id": "vC5jH-y1UAEk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.models as models"
      ],
      "metadata": {
        "id": "d7vnTPvOUCMU"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Saving and Loading Model Weights\n",
        "PyTorch models store the learned parameters in an internal state dictionary, called `state_dict`. These can be persisted via the `torch.save` method:"
      ],
      "metadata": {
        "id": "MYkXZxt4UGpJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.vgg16(pretrained=True)\n",
        "torch.save(model.state_dict(), 'model_weights.pth')"
      ],
      "metadata": {
        "id": "PUmVXFpKrp92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "473cfa1f8072414387a199f9ff86cfa0",
            "296e0f81e3014bb88498cfa36c3c2bb2",
            "7a7b5ed4d8954610a4f89896e3dcd673",
            "185d6615e70d4588bfe8263bdd4f01be",
            "31bf4fc07cce4b0c896813614112ddd5",
            "008957d3e5dc444b96480f7835c05c13",
            "b4469030380b412cb38a3725f5dccd89",
            "e7c4261315314a5ab14ac7066f5fa466",
            "ca200b2163744e38a2ac9d8816ff7df9",
            "51fdfe40d8d545f793dbeee23627db2c",
            "5cd04dc333e24fe391c8881a6ba3a4ee"
          ]
        },
        "outputId": "7b502e9d-0995-41fb-f0d4-7ebee7e72c33"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "473cfa1f8072414387a199f9ff86cfa0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0.00/528M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To load model weights, we need to create an instance of the same model first, and then load the parameters using `load_state_dict()` method."
      ],
      "metadata": {
        "id": "ynwoRIaCUd-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.vgg16() # we do not specify pretrain=True\n",
        "model.load_state_dict(torch.load('model_weights.pth'))\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "rUhS8eqlU7BN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d481893-c195-4533-a3ef-4b7da4acd0d0"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): ReLU(inplace=True)\n",
              "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): ReLU(inplace=True)\n",
              "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (20): ReLU(inplace=True)\n",
              "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (22): ReLU(inplace=True)\n",
              "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (25): ReLU(inplace=True)\n",
              "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (27): ReLU(inplace=True)\n",
              "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (29): ReLU(inplace=True)\n",
              "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: be sure to call `model.eval()` method before inferencing to set the dropout and batch normalization layers to evaluation mode. Failing to do this will yield inconsistent inference results."
      ],
      "metadata": {
        "id": "OWPFN45rVM2n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Saving and Loading Models with Shapes\n",
        "When loading model weights, we needed to instantiate the model class first, because the class deinfes the structure of a network. We may want to save the structure of this class together with the model, in which we can pass `model` (and not `model.state_dict()`) to the saving function:"
      ],
      "metadata": {
        "id": "BE5Y501FVX-m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, 'model.pth')"
      ],
      "metadata": {
        "id": "xWwWySPgVuzx"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we can load the model:"
      ],
      "metadata": {
        "id": "NApcPZ34VxBt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load('model.pth')"
      ],
      "metadata": {
        "id": "B_w2H_ixVzGu"
      },
      "execution_count": 83,
      "outputs": []
    }
  ]
}